{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract HTTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://pathumthani.moc.go.th/th/content/category/getarticles/id/114\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept-Language\": \"en-GB,en-US;q=0.9,en;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "    \"Host\": \"pathumthani.moc.go.th\",\n",
    "    \"Origin\": \"https://pathumthani.moc.go.th\",\n",
    "    \"Referer\": \"https://pathumthani.moc.go.th/th/content/category/index/id/114\",\n",
    "    \"Sec-Ch-Ua\": '\"Google Chrome\";v=\"129\", \"Not;A=Brand\";v=\"8\", \"Chromium\";v=\"129\"',\n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\",\n",
    "    \"Sec-Ch-Ua-Platform\": '\"Windows\"',\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "articles_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_index in range(1, 4):\n",
    "    data = {\n",
    "        'pageIndex': page_index \n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Request successful for page index: {page_index}:\")\n",
    "        data = response.json()\n",
    "        html_content = data.get('html')\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "        articles = soup.find_all('div', class_='inforow')\n",
    "        \n",
    "        for article in articles:\n",
    "            link_tag = article.find('a', href=True)\n",
    "            if link_tag:\n",
    "                link = f\"https://pathumthani.moc.go.th{link_tag['href']}\"\n",
    "            else:\n",
    "                link = None\n",
    "            \n",
    "            date_tag = article.find('div', class_='image-date')\n",
    "            if date_tag:\n",
    "                date = date_tag.get_text(strip=True)\n",
    "            else:\n",
    "                date = None\n",
    "            articles_data.append({'Link': link, 'Date': date})\n",
    "    else:\n",
    "        print(f\"Request failed for page index {page_index} with status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(articles_data)\n",
    "output_file = \"articles_data.xlsx\"\n",
    "df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_table_data(soup):\n",
    "    tables = soup.find_all('table')\n",
    "    if len(tables) > 1:\n",
    "        table = tables[1]\n",
    "        rows = table.find_all('tr')[2:]\n",
    "        data = []\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            cols = [ele.text.strip() for ele in cols]\n",
    "            data.append(cols)\n",
    "        return data\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    num_columns = df.shape[1]\n",
    "    column_names = ['ลำดับ', 'เลขที่ อก.', 'เลขทะเบียน', 'ชื่อโรงงาน', 'ที่อยู่', 'สถานะ']\n",
    "    df.columns = column_names[:num_columns]\n",
    "    if num_columns < len(column_names):\n",
    "        df = df.drop(columns=column_names[num_columns:], errors='ignore')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def scrape_diw_schedule(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    data = extract_table_data(soup)\n",
    "    if not data:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    if not df.empty:\n",
    "        df = clean_dataframe(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped page 1 successfully!\n",
      "Scraped page 2 successfully!\n",
      "Scraped page 3 successfully!\n",
      "Scraped page 4 successfully!\n",
      "Scraped page 5 successfully!\n",
      "Scraped page 6 successfully!\n",
      "Scraped page 7 successfully!\n",
      "Scraped page 8 successfully!\n",
      "Scraped page 9 successfully!\n",
      "Scraped page 10 successfully!\n",
      "Scraped page 11 successfully!\n",
      "Scraped page 12 successfully!\n",
      "Scraped page 13 successfully!\n",
      "Scraped page 14 successfully!\n",
      "Scraped page 15 successfully!\n",
      "Scraped page 16 successfully!\n",
      "Scraped page 17 successfully!\n",
      "Scraped page 18 successfully!\n",
      "Scraped page 19 successfully!\n",
      "Scraped page 20 successfully!\n",
      "Scraped page 21 successfully!\n",
      "Scraped page 22 successfully!\n",
      "Scraped page 23 successfully!\n",
      "Scraped page 24 successfully!\n",
      "Scraped page 25 successfully!\n",
      "Scraped page 26 successfully!\n",
      "Scraped page 27 successfully!\n",
      "Scraped page 28 successfully!\n",
      "Scraped page 29 successfully!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    base_url = \"http://reg.diw.go.th/job4/report_prov.asp?prov=13&page=\"\n",
    "    all_dfs = []\n",
    "\n",
    "    for page_num in range(1, 30):\n",
    "        url = base_url + str(page_num)\n",
    "        try:\n",
    "            df = scrape_diw_schedule(url)\n",
    "            if df is not None:\n",
    "                all_dfs.append(df)\n",
    "                print(f\"Scraped page {page_num} successfully!\")\n",
    "            else:\n",
    "                print(f\"No data on page {page_num}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping page {page_num}: {e}\")\n",
    "\n",
    "    final_df = pd.concat(all_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เลขทะเบียน</th>\n",
       "      <th>ชื่อโรงงาน</th>\n",
       "      <th>ที่อยู่</th>\n",
       "      <th>สถานะ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>จ3-50(4)-1/40ปท</td>\n",
       "      <td>บริษัท บัญชากิจ จำกัด</td>\n",
       "      <td>71 ม.14 ซ.-ถ.- ต.ลำไทรอ.ลำลูกกา จ.ปทุมธานี</td>\n",
       "      <td>ไม่เข้าข่ายเนื่องจากผลิตแอสฟัลท์ติกคอนกรีตพิจา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3-50(4)-1/43ปท</td>\n",
       "      <td>บริษัท ซีอาร์เอ กรุ๊ป จำกัด</td>\n",
       "      <td>38 ม.10ถ.วงแหวนตะวันตกสาย 37 ต.คูบางหลวงอ.ลาดห...</td>\n",
       "      <td>ไม่เข้าข่ายเนื่องจากผลิตแอสฟัลท์ติกคอนกรีตพิจา...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3-50(4)-1/31ปท</td>\n",
       "      <td>บริษัท พรีเมียลูบริแค้นท์ จำกัด</td>\n",
       "      <td>28/13 ม.3 ซ.ใจเอื้อถ.กรุงเทพ-ปทุมธานี ต.บางขะแ...</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 9/1/2557  มีข้อแนะนำ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3-50(4)-1/16ปท</td>\n",
       "      <td>บริษัท สยามลูบริแค้นท์อินดัสทรี่ จำกัด</td>\n",
       "      <td>28/8 ม.3 ซ.ใจเอื้อถ.กรุงเทพ-ปทุมธานี ต.บางขะแย...</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 12/2/2557  มีข้อแนะน...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>จ3-45(1)-1/37ปท</td>\n",
       "      <td>บริษัท ลีน่า (ประเทศไทย) จำกัด</td>\n",
       "      <td>40 ม.4ถ.รังสิต-นครนายก ต.บึงบอนอ.หนองเสือ จ.ปท...</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 24/6/2557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>จ3-42(1)-9/47ปท</td>\n",
       "      <td>บริษัท อินโน-คอนส์ (ประเทศไทย) จำกัด</td>\n",
       "      <td>22/7 ม.7 ต.คลองสี่อ.คลองหลวง จ.ปทุมธานี</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 2/12/2557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>3-7(4)-1/22ปท</td>\n",
       "      <td>บริษัท น้ำมันพืชปทุม จำกัด</td>\n",
       "      <td>29/3 ม.6 ซ.-ถ.ปทุมธานี-ลาดหลุมแก้ว ต.คูบางหลวง...</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 18/10/2559  ขอขยายโร...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>จ3-42(1)-13/58ปท</td>\n",
       "      <td>บริษัท กู๊ดไทม์ เมทัล เพสท์ จำกัด</td>\n",
       "      <td>52/1 ม.3 ต.คลองควายอ.สามโคก จ.ปทุมธานี</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 24/3/2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>จ3-91(2)-1/44ปท</td>\n",
       "      <td>บริษัท ไทยสเปเชี่ยลแก๊ส จำกัด</td>\n",
       "      <td>100/38 ม.1 ต.สามโคกอ.สามโคก จ.ปทุมธานี</td>\n",
       "      <td>ผ่านเกณฑ์  ดีพิจารณาเสร็จ 3/6/2559  มี  CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           เลขทะเบียน                              ชื่อโรงงาน  \\\n",
       "0     จ3-50(4)-1/40ปท                   บริษัท บัญชากิจ จำกัด   \n",
       "1      3-50(4)-1/43ปท             บริษัท ซีอาร์เอ กรุ๊ป จำกัด   \n",
       "2      3-50(4)-1/31ปท         บริษัท พรีเมียลูบริแค้นท์ จำกัด   \n",
       "3      3-50(4)-1/16ปท  บริษัท สยามลูบริแค้นท์อินดัสทรี่ จำกัด   \n",
       "4     จ3-45(1)-1/37ปท          บริษัท ลีน่า (ประเทศไทย) จำกัด   \n",
       "..                ...                                     ...   \n",
       "575   จ3-42(1)-9/47ปท    บริษัท อินโน-คอนส์ (ประเทศไทย) จำกัด   \n",
       "576     3-7(4)-1/22ปท              บริษัท น้ำมันพืชปทุม จำกัด   \n",
       "577  จ3-42(1)-13/58ปท       บริษัท กู๊ดไทม์ เมทัล เพสท์ จำกัด   \n",
       "578   จ3-91(2)-1/44ปท           บริษัท ไทยสเปเชี่ยลแก๊ส จำกัด   \n",
       "579              None                                    None   \n",
       "\n",
       "                                               ที่อยู่  \\\n",
       "0           71 ม.14 ซ.-ถ.- ต.ลำไทรอ.ลำลูกกา จ.ปทุมธานี   \n",
       "1    38 ม.10ถ.วงแหวนตะวันตกสาย 37 ต.คูบางหลวงอ.ลาดห...   \n",
       "2    28/13 ม.3 ซ.ใจเอื้อถ.กรุงเทพ-ปทุมธานี ต.บางขะแ...   \n",
       "3    28/8 ม.3 ซ.ใจเอื้อถ.กรุงเทพ-ปทุมธานี ต.บางขะแย...   \n",
       "4    40 ม.4ถ.รังสิต-นครนายก ต.บึงบอนอ.หนองเสือ จ.ปท...   \n",
       "..                                                 ...   \n",
       "575            22/7 ม.7 ต.คลองสี่อ.คลองหลวง จ.ปทุมธานี   \n",
       "576  29/3 ม.6 ซ.-ถ.ปทุมธานี-ลาดหลุมแก้ว ต.คูบางหลวง...   \n",
       "577             52/1 ม.3 ต.คลองควายอ.สามโคก จ.ปทุมธานี   \n",
       "578             100/38 ม.1 ต.สามโคกอ.สามโคก จ.ปทุมธานี   \n",
       "579                                               None   \n",
       "\n",
       "                                                 สถานะ  \n",
       "0    ไม่เข้าข่ายเนื่องจากผลิตแอสฟัลท์ติกคอนกรีตพิจา...  \n",
       "1    ไม่เข้าข่ายเนื่องจากผลิตแอสฟัลท์ติกคอนกรีตพิจา...  \n",
       "2    ผ่านเกณฑ์  ดีพิจารณาเสร็จ 9/1/2557  มีข้อแนะนำ...  \n",
       "3    ผ่านเกณฑ์  ดีพิจารณาเสร็จ 12/2/2557  มีข้อแนะน...  \n",
       "4                  ผ่านเกณฑ์  ดีพิจารณาเสร็จ 24/6/2557  \n",
       "..                                                 ...  \n",
       "575                ผ่านเกณฑ์  ดีพิจารณาเสร็จ 2/12/2557  \n",
       "576  ผ่านเกณฑ์  ดีพิจารณาเสร็จ 18/10/2559  ขอขยายโร...  \n",
       "577                ผ่านเกณฑ์  ดีพิจารณาเสร็จ 24/3/2559  \n",
       "578         ผ่านเกณฑ์  ดีพิจารณาเสร็จ 3/6/2559  มี  CD  \n",
       "579                                               None  \n",
       "\n",
       "[580 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df_cleaned = final_df.drop(columns=['ลำดับ', 'เลขที่ อก.'])\n",
    "final_df_cleaned['ที่อยู่'] = final_df_cleaned['ที่อยู่'].str.replace(r'\\r\\n|\\t', '', regex=True).str.strip()\n",
    "final_df_cleaned['สถานะ'] = final_df_cleaned['สถานะ'].str.replace(r'\\r\\n|\\t', '', regex=True).str.strip()\n",
    "final_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_cleaned.to_csv('ข้อมูลโรงงานที่ประเมินความเสี่ยงจังหวัดปทุมธานี.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
